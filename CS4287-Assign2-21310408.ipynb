{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of two CNN\n",
    "- Tadhg Ryan 21310408\n",
    "- <>\n",
    "\n",
    "##### Code executes to end with no errors\n",
    "\n",
    "## Resources:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "dataset_path = kagglehub.dataset_download(\"muratkokludataset/rice-image-dataset\") + \"\\\\Rice_Image_Dataset\"\n",
    "\n",
    "print(\"Path to dataset files:\", dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 250\n",
    "IMG_WIDTH = 250\n",
    "K = 5\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "MAX_SIZE_DATASET = 75000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data in\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create the full dataset (without splitting for validation)\n",
    "full_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',  # Load labels in grayscale\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Get class names for later use\n",
    "class_names = full_dataset.class_names\n",
    "\n",
    "full_datasset = full_dataset.take(MAX_SIZE_DATASET // BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 9\n",
    "\n",
    "# Select a sample of images to display\n",
    "images_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Iterate through the dataset and collect enough images\n",
    "i = 0\n",
    "for image_batch, label_batch in full_dataset:\n",
    "    if i >= num_images:\n",
    "        break\n",
    "    images_list.append(image_batch)\n",
    "    labels_list.append(label_batch)\n",
    "    i = i + 1\n",
    "if i != num_images:\n",
    "    num_images = i\n",
    "\n",
    "# Concatenate the batches into a single array\n",
    "images_array = tf.concat(images_list, axis=0)\n",
    "labels_array = tf.concat(labels_list, axis=0)\n",
    "\n",
    "# Now, select the first `num_images` images and labels to display\n",
    "images_to_display = images_array[:num_images]\n",
    "labels_to_display = labels_array[:num_images]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Plot the images in a grid\n",
    "for i in range(num_images):\n",
    "\tax = plt.subplot(3, 3, i + 1)  # 3 rows, 3 columns\n",
    "\tplt.imshow(images_to_display[i].numpy().squeeze(), cmap='gray')  # Convert tensor to numpy array and display\n",
    "\tplt.title(class_names[labels_to_display[i].numpy()])  # Use class names for titles\n",
    "\tplt.axis(\"off\")  # Hide axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Augmentation\n",
    "# def preprocess_image(image, label):\n",
    "#     # Explicitly reshape to correct size\n",
    "#     image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "#     image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, 1])  # For grayscale images\n",
    "#     return image, label\n",
    "\n",
    "# # Apply the preprocessing function\n",
    "# full_dataset = full_dataset.map(preprocess_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model 1\n",
    "\n",
    "# Step 1: Import necessary libraries\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Step 2: Define the Inception module\n",
    "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj):\n",
    "    # 1x1 Convolution branch\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 3x3 Convolution branch\n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)\n",
    "\n",
    "    # 5x5 Convolution branch\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)\n",
    "\n",
    "    # 3x3 MaxPooling branch\n",
    "    pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n",
    "\n",
    "    # Concatenate all branches\n",
    "    output = Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5, pool_proj])\n",
    "    return output\n",
    "\n",
    "# Step 3: Define the GoogleLeNet model\n",
    "def googlenet(input_shape=(250, 250, 1), num_classes=5):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Initial layers (similar to VGG)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Inception modules\n",
    "    x = inception_module(x, 64, 96, 128, 16, 32, 32)\n",
    "    x = inception_module(x, 128, 128, 192, 32, 96, 64)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, 192, 96, 208, 16, 48, 64)\n",
    "    x = inception_module(x, 160, 112, 224, 24, 64, 64)\n",
    "    x = inception_module(x, 128, 128, 256, 24, 64, 64)\n",
    "    x = inception_module(x, 112, 144, 288, 32, 64, 64)\n",
    "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = inception_module(x, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "    # Average pooling layer\n",
    "    x = AveragePooling2D((7, 7), strides=(1, 1), padding='valid')(x)\n",
    "\n",
    "    # Dropout layer\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # Fully connected layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(num_classes, activation='softmax', name=\"outputs\")(x)\n",
    "\n",
    "    # Model\n",
    "    model = Model(input_layer, x, name=\"GoogleLeNet\")\n",
    "    return model\n",
    "\n",
    "# Step 4: Instantiate the model\n",
    "googleLeNetModel = googlenet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1), num_classes=len(class_names))\n",
    "\n",
    "# Display model summary\n",
    "googleLeNetModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model 2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def SimpleNet(input_shape=(250, 250, 1), num_classes=5):\n",
    "    model = Sequential([\n",
    "    \t# Input layer\n",
    "    \tInput(shape=input_shape),\n",
    "\t\tConv2D(filters=16, kernel_size=(7, 7), activation=\"relu\"),\n",
    "\t\tMaxPooling2D((2,2)),\n",
    "\t\tConv2D(filters=32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "\t\tMaxPooling2D((2,2)),\n",
    "\t\tConv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "\t\tMaxPooling2D((2,2)),\n",
    "\t\tConv2D(filters=128, kernel_size=(3, 3),activation=\"relu\"),\n",
    "\t\tMaxPooling2D((2,2)),\n",
    "\n",
    "    \tFlatten(),\n",
    "     \n",
    "    \t# Dropout layer\n",
    "    \tDropout(0.4),\n",
    "     \n",
    "    \t# Fully connected layer\n",
    "    \tDense(num_classes, activation='softmax', name=\"outputs\"),\n",
    "\t])\n",
    "\n",
    "    return model\n",
    "\n",
    "SimpleNet().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining k-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def RunKFold(modelFunction, optimiser, loss_function):\n",
    "\tAUTOTUNE = tf.data.AUTOTUNE\n",
    "\tfull_dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\t# Create a KFold object\n",
    "\tkf = KFold(n_splits=K, shuffle=True)\n",
    " \n",
    "\tdataset_size = len(full_dataset)\n",
    "\tindices = np.arange(dataset_size)\n",
    "\t\n",
    "\t# Prepare to collect results\n",
    "\tfold_results = []\n",
    "\n",
    "\t# Iterate over K folds\n",
    "\tfor fold, (train_index, val_index) in enumerate(kf.split(indices)):\n",
    "\t\tprint(f\"==================== Fold: {fold+1} ====================\")\n",
    "\t\ttrain = full_dataset.take(1)\n",
    "\t\tfor i in range(len(train_index)):\n",
    "\t\t\ttrain = full_dataset.skip(train_index[i-1]).take(1).concatenate(train)\n",
    "\t\ttrain.cache().prefetch(tf.data.AUTOTUNE)\n",
    "   \n",
    "\t\tval = full_dataset.take(1)\n",
    "\t\tfor i in range(len(val_index)):\n",
    "\t\t\tval = full_dataset.skip(val_index[i-1]).take(1).concatenate(val)\n",
    "\t\tval.cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "  \t\t# Recreate the model to avoid reusing weights\n",
    "\t\tmodel = modelFunction(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1), num_classes=len(class_names))\n",
    "\t\n",
    "\t\t# Compile the model\n",
    "\t\tmodel.compile(optimizer=optimiser, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "\t\t# Train the model on the training dataset\n",
    "\t\tmodel.fit(train, epochs=EPOCHS, validation_data=val)\n",
    "\n",
    "\t\t# Evaluate on the validation dataset and store the results\n",
    "\t\tval_loss, val_accuracy = model.evaluate(val)\n",
    "\t\tfold_results.append(val_accuracy)\n",
    "\n",
    "\t# Output the results\n",
    "\tprint(f'Cross-Validation Results: {fold_results}')\n",
    "\tprint(f'Mean Accuracy: {sum(fold_results) / K}')\n",
    "\treturn fold_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Models with k-fold cross validation\n",
    "from tensorflow.keras import optimizers, losses\n",
    "\n",
    "optimiser = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_function = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# RunKFold(googlenet, optimiser, loss_function)\n",
    "RunKFold(SimpleNet, optimiser, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
