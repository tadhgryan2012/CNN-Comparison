{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of two CNN\n",
    "- Tadhg Ryan 21310408\n",
    "- <>\n",
    "\n",
    "##### Code executes to end with no errors\n",
    "\n",
    "## Resources:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "dataset_path = kagglehub.dataset_download(\"muratkokludataset/rice-image-dataset\") + \"\\\\Rice_Image_Dataset\"\n",
    "\n",
    "print(\"Path to dataset files:\", dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "IMG_HEIGHT = 250\n",
    "IMG_WIDTH = 250\n",
    "K = 5\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data in\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create the full dataset (without splitting for validation)\n",
    "full_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',  # Load images in grayscale\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Get class names for later use\n",
    "class_names = full_dataset.class_names\n",
    "\n",
    "# Cache and prefetch the full dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "full_dataset = full_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 9\n",
    "\n",
    "# Select a sample of images to display\n",
    "image_batch, label_batch = next(iter(full_dataset))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Plot the images in a grid\n",
    "for i in range(num_images):\n",
    "    ax = plt.subplot(3, 3, i + 1)  # 3 rows, 3 columns\n",
    "    plt.imshow(image_batch[i].numpy().squeeze(), cmap='gray')  # Convert tensor to numpy array and display\n",
    "    plt.title(class_names[label_batch[i].numpy()])  # Use class names for titles\n",
    "    plt.axis(\"off\")  # Hide axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Augmentation\n",
    "# def preprocess_image(image, label):\n",
    "#     # Explicitly reshape to correct size\n",
    "#     image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "#     image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, 1])  # For grayscale images\n",
    "#     return image, label\n",
    "\n",
    "# # Apply the preprocessing function\n",
    "# full_dataset = full_dataset.map(preprocess_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model 1\n",
    "\n",
    "# Step 1: Import necessary libraries\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Step 2: Define the Inception module\n",
    "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj):\n",
    "    # 1x1 Convolution branch\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 3x3 Convolution branch\n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)\n",
    "\n",
    "    # 5x5 Convolution branch\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)\n",
    "\n",
    "    # 3x3 MaxPooling branch\n",
    "    pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n",
    "\n",
    "    # Concatenate all branches\n",
    "    output = Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5, pool_proj])\n",
    "    return output\n",
    "\n",
    "# Step 3: Define the GoogleLeNet model\n",
    "def googlenet(input_shape=(250, 250, 1), num_classes=5):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Initial layers (similar to VGG)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Inception modules\n",
    "    x = inception_module(x, 64, 96, 128, 16, 32, 32)\n",
    "    x = inception_module(x, 128, 128, 192, 32, 96, 64)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, 192, 96, 208, 16, 48, 64)\n",
    "    x = inception_module(x, 160, 112, 224, 24, 64, 64)\n",
    "    x = inception_module(x, 128, 128, 256, 24, 64, 64)\n",
    "    x = inception_module(x, 112, 144, 288, 32, 64, 64)\n",
    "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = inception_module(x, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "    # Average pooling layer\n",
    "    x = AveragePooling2D((7, 7), strides=(1, 1), padding='valid')(x)\n",
    "\n",
    "    # Dropout layer\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # Fully connected layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(num_classes, activation='softmax', name=\"outputs\")(x)\n",
    "\n",
    "    # Model\n",
    "    model = Model(input_layer, x, name=\"GoogleLeNet\")\n",
    "    return model\n",
    "\n",
    "# Step 4: Instantiate the model\n",
    "googleLeNetModel = googlenet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1), num_classes=len(class_names))\n",
    "\n",
    "# Display model summary\n",
    "googleLeNetModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model 1 with k-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import optimizers, losses\n",
    "import numpy as np\n",
    "\n",
    "OPTIMISER = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "LOSS_FUNCTION = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# Get dataset size (number of batches)\n",
    "dataset_size = len(full_dataset)\n",
    "indices = np.arange(dataset_size)\n",
    "\n",
    "# Prepare to collect results\n",
    "fold_results = []\n",
    "\n",
    "# Iterate over K folds\n",
    "for train_index, val_index in kf.split(indices):\n",
    "    # Define the training and validation datasets using slicing\n",
    "    train_dataset = full_dataset.skip(train_index[0]).take(len(train_index))\n",
    "    val_dataset = full_dataset.skip(val_index[0]).take(len(val_index))\n",
    "\n",
    "    # Cache and prefetch for performance\n",
    "    train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    val_dataset = val_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    # Recreate the model to avoid reusing weights\n",
    "    googleLeNetModel = googlenet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1), num_classes=len(class_names))\n",
    "    \n",
    "    # Compile the model\n",
    "    googleLeNetModel.compile(optimizer=OPTIMISER, loss=LOSS_FUNCTION, metrics=['accuracy'])\n",
    "\n",
    "    # Train the model on the training dataset\n",
    "    googleLeNetModel.fit(train_dataset, epochs=EPOCHS, validation_data=val_dataset)\n",
    "\n",
    "    # Evaluate on the validation dataset and store the results\n",
    "    val_loss, val_accuracy = googleLeNetModel.evaluate(val_dataset)\n",
    "    fold_results.append(val_accuracy)\n",
    "\n",
    "# Output the results\n",
    "print(f'Cross-Validation Results: {fold_results}')\n",
    "print(f'Mean Accuracy: {sum(fold_results) / K}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Model 2 with k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics of both Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
