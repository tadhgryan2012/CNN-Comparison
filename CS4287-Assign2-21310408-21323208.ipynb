{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of two CNN\n",
    "- Tadhg Ryan 21310408\n",
    "- Szymon Szulc 21323208\n",
    "\n",
    "##### Code executes to end with no errors\n",
    "\n",
    "## Resources:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "dataset_path = kagglehub.dataset_download(\"muratkokludataset/rice-image-dataset\") + \"\\\\Rice_Image_Dataset\"\n",
    "\n",
    "print(\"Path to dataset files:\", dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 250\n",
    "IMG_WIDTH = 250\n",
    "K = 3\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "MAX_SIZE_DATASET = 1000\n",
    "NUM_OF_BATCHES = MAX_SIZE_DATASET // BATCH_SIZE\n",
    "RESIZED_SIZE = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data in\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create the full dataset (without splitting for validation)\n",
    "train_dataset, test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',  # Load labels in grayscale\n",
    "    shuffle=True,\n",
    "    validation_split=0.004,\n",
    "    subset=\"both\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Get class names for later use\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "train_dataset = train_dataset.take(NUM_OF_BATCHES)\n",
    "print(f\"Taking {NUM_OF_BATCHES} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the data augmentation pipeline\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"), \t\t# Flip horizontally\n",
    "    layers.RandomZoom(-0.2, 0.2),        \t\t\t\t# Zoom in on the image\n",
    "    layers.RandomRotation(0.2),          \t\t\t\t# Randomly rotate image\n",
    "    layers.RandomBrightness(factor=(-0.2, 0.2)),\n",
    "])\n",
    "data_scaling = tf.keras.Sequential([\n",
    "    layers.Resizing(RESIZED_SIZE, RESIZED_SIZE),\t\t# Resize to desired dimensions\n",
    "])\n",
    "data_normalisation = tf.keras.Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "# Define functions to apply the augmentation\n",
    "def augment_image(image, label):\n",
    "    image = data_augmentation(image, training=True)\n",
    "    return image, label\n",
    "\n",
    "def scale_image(image, label):\n",
    "    image = data_scaling(image, training=True)\n",
    "    return image, label\n",
    "\n",
    "def normalise_image(image, label):\n",
    "    image = data_normalisation(image)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "num_images = 9  # Number of images to display\n",
    "\n",
    "# Create lists to store images and augmented images\n",
    "original_images = []\n",
    "augmented_images = []\n",
    "labels_list = []\n",
    "\n",
    "# Iterate through the dataset and collect images and their augmented versions\n",
    "i = 0\n",
    "for image_batch, label_batch in train_dataset:\n",
    "    if i >= num_images:\n",
    "        break\n",
    "    original_images.append(image_batch)  # Save original image\n",
    "    augmented_image = augment_image(image_batch, None)[0]\n",
    "    augmented_image = scale_image(augmented_image, None)[0]\n",
    "    augmented_image = normalise_image(augmented_image, None)[0]\n",
    "    augmented_images.append(augmented_image)  # Save augmented image\n",
    "    labels_list.append(label_batch)\n",
    "    i += BATCH_SIZE\n",
    "\n",
    "# Concatenate the batches into single arrays\n",
    "original_images_array = tf.concat(original_images, axis=0)\n",
    "augmented_images_array = tf.concat(augmented_images, axis=0)\n",
    "labels_array = tf.concat(labels_list, axis=0)\n",
    "\n",
    "# Select the first `num_images` images and labels to display\n",
    "original_images_to_display = original_images_array[:num_images]\n",
    "augmented_images_to_display = augmented_images_array[:num_images]\n",
    "labels_to_display = labels_array[:num_images]\n",
    "\n",
    "# Plot the images in a grid\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Plot original images\n",
    "    ax = plt.subplot(3, 6, 2 * i + 1)  # Adjust for both original and augmented\n",
    "    plt.imshow(original_images_to_display[i].numpy().squeeze(), cmap='gray')\n",
    "    plt.title(f\"Original - {class_names[labels_to_display[i].numpy()]}\")  # Show class name\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Plot augmented images\n",
    "    ax = plt.subplot(3, 6, 2 * i + 2)\n",
    "    plt.imshow(augmented_images_to_display[i].numpy().squeeze(), cmap='gray')\n",
    "    plt.title(f\"Augmented - {class_names[labels_to_display[i].numpy()]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "augmented_train_dataset         = train_dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "scale_augmented_train_dataset   = augmented_train_dataset.map(scale_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset                   = scale_augmented_train_dataset.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "scale_test_dataset              = test_dataset.map(scale_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset                    = scale_test_dataset.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model 1\n",
    "\n",
    "# Step 1: Import necessary libraries\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Step 2: Define the Inception module\n",
    "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj):\n",
    "    # 1x1 Convolution branch\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 3x3 Convolution branch\n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)\n",
    "\n",
    "    # 5x5 Convolution branch\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)\n",
    "\n",
    "    # 3x3 MaxPooling branch\n",
    "    pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n",
    "\n",
    "    # Concatenate all branches\n",
    "    output = Concatenate(axis=-1)([conv_1x1, conv_3x3, conv_5x5, pool_proj])\n",
    "    return output\n",
    "\n",
    "# Step 3: Define the GoogleLeNet model\n",
    "def GoogleLeNet(input_shape=(224, 224, 1), num_classes=5):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    resized_layer = layers.Resizing(224, 224)(input_layer)\n",
    "\n",
    "    # Initial layers (similar to VGG)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(resized_layer)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Inception modules\n",
    "    x = inception_module(x, 64, 96, 128, 16, 32, 32)\n",
    "    x = inception_module(x, 128, 128, 192, 32, 96, 64)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, 192, 96, 208, 16, 48, 64)\n",
    "    x = inception_module(x, 160, 112, 224, 24, 64, 64)\n",
    "    x = inception_module(x, 128, 128, 256, 24, 64, 64)\n",
    "    x = inception_module(x, 112, 144, 288, 32, 64, 64)\n",
    "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = inception_module(x, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "    # Average pooling layer\n",
    "    x = AveragePooling2D((3, 3), strides=(1, 1), padding='valid')(x)\n",
    "\n",
    "    # Dropout layer\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # Fully connected layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(num_classes, activation='softmax', name=\"outputs\")(x)\n",
    "\n",
    "    # Model\n",
    "    model = Model(input_layer, x, name=\"GoogleLeNet\")\n",
    "    return model\n",
    "\n",
    "# Step 4: Instantiate the model\n",
    "googleLeNetModel = GoogleLeNet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1), num_classes=len(class_names))\n",
    "\n",
    "# Display model summary\n",
    "googleLeNetModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model 2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def SimpleNet(input_shape=(250, 250, 1), num_classes=5):\n",
    "    model = Sequential([\n",
    "    \t# Input layer\n",
    "\t\tInput(input_shape),\n",
    "\t\tlayers.Resizing(224, 224),\n",
    "\t\tConv2D(filters=16, kernel_size=(7, 7), activation=\"relu\"),\n",
    "\t\tMaxPooling2D((2,2)),\n",
    "\t\tConv2D(filters=32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "\t\tMaxPooling2D((2,2)),\n",
    "\t\tConv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "\t\tMaxPooling2D((2,2)),\n",
    "\t\tConv2D(filters=128, kernel_size=(3, 3),activation=\"relu\"),\n",
    "\t\tMaxPooling2D((2,2)),\n",
    "\n",
    "    \tFlatten(),\n",
    "     \n",
    "    \t# Dropout layer\n",
    "    \tDropout(0.4),\n",
    "     \n",
    "    \t# Fully connected layer\n",
    "    \tDense(num_classes, activation='softmax', name=\"outputs\"),\n",
    "\t])\n",
    "\n",
    "    return model\n",
    "\n",
    "SimpleNet().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 define\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def VGG16(input_shape=(224, 224, 1), num_classes=5, dropout_rate=0.5):\n",
    "\tmodel = models.Sequential()\n",
    "\n",
    "\tmodel.add(layers.Input(input_shape))\n",
    "\tmodel.add(layers.Resizing(224, 224))\n",
    " \n",
    "\t# Block 1\n",
    "\tmodel.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    " \n",
    "\t# Block 2\n",
    "\tmodel.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    " \n",
    "\t# Block 3\n",
    "\tmodel.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    " \n",
    "\t# Block 4\n",
    "\tmodel.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    " \n",
    "\t# Block 5\n",
    "\tmodel.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    " \n",
    "\t# Fully connected layers\n",
    "\tmodel.add(layers.Flatten())\n",
    "\tmodel.add(layers.Dense(4096, activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Dropout(dropout_rate))\n",
    "\tmodel.add(layers.Dense(4096, activation='relu'))\n",
    "\tmodel.add(layers.BatchNormalization())\n",
    "\tmodel.add(layers.Dropout(dropout_rate))\n",
    "\tmodel.add(layers.Dense(num_classes, activation='softmax'))  # Output layer for 5 classes\n",
    " \n",
    "\treturn model\n",
    "\n",
    "VGG16().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining k-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def RunKFold(modelFunction, optimiser_class, loss_function):\n",
    "\t# Create a KFold object\n",
    "\tkf = KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "\tindices = np.arange(len(train_dataset))\n",
    "\n",
    "\tbest_model = None\n",
    "\tbest_val_loss = float('inf')\n",
    "\n",
    "\t# Iterate over K folds\n",
    "\tfor fold, (train_index, val_index) in enumerate(kf.split(indices)):\n",
    "\t\tprint(f\"==================== Fold: {fold+1} ====================\")\n",
    "\t\ttrain = train_dataset.skip(train_index[0]).take(1)\n",
    "\t\tfor index in train_index[1:]:\n",
    "\t\t\ttrain = ((train_dataset.skip(index)).take(1)).concatenate(train)\n",
    "\t\ttrain.cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\t\tval = train_dataset.skip(val_index[0]).take(1)\n",
    "\t\tfor index in val_index[1:]:\n",
    "\t\t\tval = ((train_dataset.skip(index)).take(1)).concatenate(val)\n",
    "\t\tval.cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "  \t\t# Recreate the model to avoid reusing weights\n",
    "\t\tmodel = modelFunction(input_shape=(RESIZED_SIZE, RESIZED_SIZE, 1), num_classes=len(class_names))\n",
    "\n",
    "\t\toptimiser = optimiser_class(learning_rate=LEARNING_RATE)\n",
    "\n",
    "\t\t# Compile the model\n",
    "\t\tmodel.compile(optimizer=optimiser, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "\t\t# Train the model on the training dataset\n",
    "\t\tmodel.fit(train, epochs=EPOCHS, validation_data=val)\n",
    "\t\tval_loss = min(model.history.history['val_loss'])\n",
    "  \n",
    "\t\t# Update the best model if this fold is better\n",
    "\t\tif val_loss < best_val_loss:\n",
    "\t\t\tbest_val_loss = val_loss\n",
    "\t\t\tbest_model = model\n",
    "\n",
    "\treturn best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Models with k-fold cross validation\n",
    "from tensorflow.keras import optimizers, losses\n",
    "\n",
    "train_dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ModelFunctions = [VGG16, GoogleLeNet, SimpleNet]\n",
    "ModelNames = [\"VGG16\", \"GoogleLeNet\", \"SimpleNet\"]\n",
    "bestModels = []\n",
    "\n",
    "for model in ModelFunctions:\n",
    "\toptimiser = optimizers.Adam\n",
    "\tloss_function = losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\tbestModels.append(RunKFold(model, optimiser, loss_function))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_models(models, test_dataset, class_names):\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"================ Metrics for {ModelNames[i]} Model ================\")\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for images, labels in test_dataset:\n",
    "            y_true.extend(labels.numpy())\n",
    "            predictions = model.predict(images)\n",
    "            y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(f\"Confusion Matrix for Model {i+1}\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, zero_division=0)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        metrics = [precision, recall, f1]\n",
    "        metric_names = [\"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "        for ax, metric, name in zip(axes, metrics, metric_names):\n",
    "            ax.bar(class_names, metric, color='skyblue')\n",
    "            ax.set_title(name)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_xlabel(\"Class\")\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "        axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"======================================================\\n\")\n",
    "\n",
    "evaluate_models(bestModels, test_dataset, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
